{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5962230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "\n",
    "# from tensorflow import keras\n",
    "# from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "923f1ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:\\\\Users\\\\jolged\\\\PycharmProjects\\\\2022-11_Data_science_Code_Academy\\\\Final_Project\\\\AutoAptikimas\\\\\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adf973eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 56 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing_0_batch_of_images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▊                                                                   | 1/5 [00:12<00:48, 12.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing_1_batch_of_images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:29<00:46, 15.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing_2_batch_of_images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:41<00:27, 13.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing_3_batch_of_images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:56<00:14, 14.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing_4_batch_of_images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:06<00:00, 13.29s/it]\n"
     ]
    }
   ],
   "source": [
    "total_number_of_files = 300\n",
    "\n",
    "# Define directories for input and output\n",
    "input_dir = data_path + f'data\\\\{version}\\\\for_augmentations'\n",
    "output_dir = data_path + f'data\\\\{version}\\\\augmentations'\n",
    "\n",
    "batch_size = len(os.listdir(input_dir+\"\\\\batch\"))\n",
    "number_of_files_to_generate = total_number_of_files - batch_size\n",
    "num_of_augmentations = math.ceil(number_of_files_to_generate/batch_size)\n",
    "\n",
    "# Create the ImageDataGenerator object and define augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    brightness_range=[0.4, 0.8],\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='reflect')\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        directory=input_dir,\n",
    "        target_size=(1024, 768),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False) \n",
    "\n",
    "for i in tqdm(range(0, num_of_augmentations)):\n",
    "    for batch in generator:\n",
    "        print(f'processing_{i+1}_batch_of_images')\n",
    "        for image_index in range(0, batch[0].shape[0]):\n",
    "            image = batch[0][image_index, :, :, :]\n",
    "            image_name = generator.filenames[image_index].split('\\\\')[1].split('.')\n",
    "            new_image_name = f'{image_name[0]}_{image_name[1]}_augmentation_{i}.jpg'\n",
    "            path_to_save_image = os.path.join(output_dir, new_image_name)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            cv2.imwrite(path_to_save_image, image)\n",
    "            prigeneruota_failu = len(os.listdir(output_dir))\n",
    "            if  prigeneruota_failu == number_of_files_to_generate:\n",
    "                break\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JupyterNB",
   "language": "python",
   "name": "jupyternb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
